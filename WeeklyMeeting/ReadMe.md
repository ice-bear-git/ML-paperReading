# The Weekly Meeting
Good online courses: 
* [MIT Deep Learning](http://introtodeeplearning.com)
* [Uwaterloo Intro to ML](https://cs.uwaterloo.ca/~ppoupart/teaching/cs480-spring19/schedule.html)  

Zoom Links: [here](https://zoom.us/j/95071756890)


## Mar 21

### NLP
A famous source: [its Github](https://github.com/allenai/allennlp)


### MPC
Model-Preductuve Control, here is a [quick demo](https://github.com/mcarfagno/mpc_python)   
I found that's hard to translate pseudo-code 


### The Corresponding Website for [Uwaterloo Intro to ML](https://cs.uwaterloo.ca/~ppoupart/teaching/cs480-spring19/schedule.html)
Que:
1. The Computational Graph is elegant, but it's hard to make sense for me.  

![Figure2](https://github.com/ice-bear-git/ML-paperReading/blob/main/WeeklyMeeting/TF-2.PNG)

2. Is the Fully Connection (like dense Net) character matters? ---- The reason of long range dependency.  
![Figure1](https://github.com/ice-bear-git/ML-paperReading/blob/main/WeeklyMeeting/TF-1.PNG)

![Figure3](https://github.com/ice-bear-git/ML-paperReading/blob/main/WeeklyMeeting/TF-3.PNG)
![Figure4](https://github.com/ice-bear-git/ML-paperReading/blob/main/WeeklyMeeting/TF-4.PNG)

### The MIT's course is released --- just start watching